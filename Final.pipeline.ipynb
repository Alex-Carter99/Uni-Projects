{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e518604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DATA LOADING AND PREPARATION\n",
      "======================================================================\n",
      "Loading combined dataset from Anonymisation.ipynb output...\n",
      "\n",
      "Loaded Combined.csv: 3,957 rows, 19 columns\n",
      "\n",
      "Filtered to binary classes: 3,957 rows (removed 0)\n",
      "\n",
      "Dataset: 3,957 samples, 17 features\n",
      "Target classes: {'Failed': 400, 'Passed': 3557}\n",
      "\n",
      "Train set: 3,165 samples\n",
      "Test set: 792 samples\n",
      "Train class distribution: {'Failed': 320, 'Passed': 2845}\n",
      "Test class distribution: {'Failed': 80, 'Passed': 712}\n",
      "\n",
      "======================================================================\n",
      "DATA PREPARATION COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Ready for classifier testing and optimization.\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# DATA LOADING AND PREPARATION\n",
    "# =====================================================================\n",
    "# Load the combined dataset from Anonymisation.ipynb and prepare for classification\n",
    "# Consistent with methodology described in Chapter 4 of the dissertation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration \n",
    "TARGET_COL = \"Recorded Video Interview\"\n",
    "BINARY_CLASSIFICATION = True\n",
    "TARGET_BINARY_VALUES = [\"Passed\", \"Failed\"]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DATA LOADING AND PREPARATION\")\n",
    "print(\"=\"*70)\n",
    "print(\"Loading combined dataset from Anonymisation.ipynb output...\")\n",
    "\n",
    "# Load the combined dataset\n",
    "combined_file = 'Combined.csv'\n",
    "try:\n",
    "    df_combined = pd.read_csv(combined_file)\n",
    "    print(f\"\\nLoaded {combined_file}: {df_combined.shape[0]:,} rows, {df_combined.shape[1]} columns\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\nError: {combined_file} not found.\")\n",
    "    print(\"   The combined dataset file is required. Ensure Anonymisation.ipynb has been executed.\")\n",
    "    df_combined = None\n",
    "\n",
    "if df_combined is not None:\n",
    "    # Check if target column exists\n",
    "    if TARGET_COL not in df_combined.columns:\n",
    "        print(f\"\\nError: Target column '{TARGET_COL}' not found in combined dataset.\")\n",
    "        print(f\"   Available columns: {df_combined.columns.tolist()}\")\n",
    "    else:\n",
    "        # Prepare features and target\n",
    "        X = df_combined.drop(columns=[TARGET_COL, 'dataset_year'] if 'dataset_year' in df_combined.columns else [TARGET_COL]).copy()\n",
    "        y = df_combined[TARGET_COL].copy()\n",
    "        \n",
    "        # Filter to binary classification (as per Chapter 4, Section 4.2)\n",
    "        if BINARY_CLASSIFICATION:\n",
    "            target_normalized = y.astype(str).str.strip().str.lower()\n",
    "            binary_normalized = [v.lower().strip() for v in TARGET_BINARY_VALUES]\n",
    "            filter_mask = target_normalized.isin(binary_normalized)\n",
    "            \n",
    "            rows_before = len(X)\n",
    "            X = X[filter_mask].copy().reset_index(drop=True)\n",
    "            y = y[filter_mask].copy().reset_index(drop=True)\n",
    "            rows_after = len(X)\n",
    "            \n",
    "            print(f\"\\nFiltered to binary classes: {rows_after:,} rows (removed {rows_before - rows_after:,})\")\n",
    "        \n",
    "        # Encode target\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_encoded = label_encoder.fit_transform(y)\n",
    "        class_names = label_encoder.classes_\n",
    "        \n",
    "        print(f\"\\nDataset: {X.shape[0]:,} samples, {X.shape[1]} features\")\n",
    "        print(f\"Target classes: {dict(zip(class_names, np.bincount(y_encoded)))}\")\n",
    "        \n",
    "        # Train/Test Split (80/20 stratified, as per Chapter 4, Section 4.2)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y_encoded,\n",
    "            test_size=0.2,\n",
    "            stratify=y_encoded,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nTrain set: {X_train.shape[0]:,} samples\")\n",
    "        print(f\"Test set: {X_test.shape[0]:,} samples\")\n",
    "        print(f\"Train class distribution: {dict(zip(class_names, np.bincount(y_train)))}\")\n",
    "        print(f\"Test class distribution: {dict(zip(class_names, np.bincount(y_test)))}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"DATA PREPARATION COMPLETE\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"\\nReady for classifier testing and optimization.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4615ef89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PREPROCESSING PIPELINE SETUP\n",
      "======================================================================\n",
      "\n",
      "Numeric features: 6\n",
      "Categorical features: 11\n",
      "\n",
      "Preprocessing pipeline configured successfully\n",
      "  - Numeric: median imputation + standardization\n",
      "  - Categorical: 'missing' category + one-hot encoding (max 50 categories)\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# PREPROCESSING PIPELINE SETUP\n",
    "# =====================================================================\n",
    "# Set up preprocessing pipeline for classification models\n",
    "# Consistent with Chapter 4, Section 4.2 of the dissertation\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PREPROCESSING PIPELINE SETUP\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if 'X_train' not in locals():\n",
    "    print(\"Error: X_train not found. Ensure the data loading cell has been executed.\")\n",
    "else:\n",
    "    # Identify numeric and categorical columns\n",
    "    numeric_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    categorical_cols = X_train.select_dtypes(include=['object', 'string', 'category']).columns.tolist()\n",
    "    \n",
    "    print(f\"\\nNumeric features: {len(numeric_cols)}\")\n",
    "    print(f\"Categorical features: {len(categorical_cols)}\")\n",
    "    \n",
    "    # Numeric pipeline: median imputation + scaling (as per Chapter 4, Section 4.2)\n",
    "    numeric_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    # Categorical pipeline: constant imputation + one-hot encoding (as per Chapter 4, Section 4.2)\n",
    "    try:\n",
    "        # Try new API (sklearn >= 1.4)\n",
    "        categorical_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False, max_categories=50))\n",
    "        ])\n",
    "    except TypeError:\n",
    "        # Fall back to old API (sklearn < 1.4)\n",
    "        categorical_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "        ])\n",
    "    \n",
    "    # Combine preprocessing\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('numeric', numeric_pipeline, numeric_cols),\n",
    "        ('categorical', categorical_pipeline, categorical_cols)\n",
    "    ])\n",
    "    \n",
    "    print(\"\\nPreprocessing pipeline configured successfully\")\n",
    "    print(\"  - Numeric: median imputation + standardization\")\n",
    "    print(\"  - Categorical: 'missing' category + one-hot encoding (max 50 categories)\")\n",
    "    print(\"\\n\" + \"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "707a046f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "INITIAL MODEL TESTING: MLP NEURAL NETWORK\n",
      "======================================================================\n",
      "Testing Multi-Layer Perceptron as initial classifier\n",
      "(As per Chapter 4, Section 4.4 - Model Selection)\n",
      "\n",
      "MLP Architecture:\n",
      "  Hidden layers: (64, 32)\n",
      "  Activation: relu\n",
      "  L2 regularization (alpha): 0.001\n",
      "  Early stopping: True\n",
      "  Max iterations: 500\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Cross-Validation (5-fold, stratified)\n",
      "----------------------------------------------------------------------\n",
      "CV Accuracy:        0.8986 (+/- 0.0092)\n",
      "CV Balanced Acc:    0.6080 (+/- 0.1157)\n",
      "CV F1 (macro):      0.6227 (+/- 0.1549)\n",
      "CV ROC-AUC:         0.8893 (+/- 0.0227)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Test Set Evaluation\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Test Set Metrics:\n",
      "  Accuracy:          0.8990\n",
      "  Balanced Accuracy: 0.5277\n",
      "  F1-Score (macro):  0.5288\n",
      "  ROC-AUC:           0.8974\n",
      "\n",
      "======================================================================\n",
      "MLP TESTING COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Note: MLP demonstrated poor performance with very low balanced accuracy,\n",
      "indicating it was not an effective classifier for this dataset.\n",
      "Proceeding to test alternative classifiers...\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# INITIAL MODEL TESTING: MLP NEURAL NETWORK\n",
    "# =====================================================================\n",
    "# Testing Multi-Layer Perceptron as initial classifier\n",
    "# As described in Chapter 4, Section 4.4 of the dissertation\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, \n",
    "    roc_auc_score, balanced_accuracy_score,\n",
    "    accuracy_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"INITIAL MODEL TESTING: MLP NEURAL NETWORK\")\n",
    "print(\"=\"*70)\n",
    "print(\"Testing Multi-Layer Perceptron as initial classifier\")\n",
    "print(\"(As per Chapter 4, Section 4.4 - Model Selection)\")\n",
    "\n",
    "if 'X_train' not in locals() or 'preprocessor' not in locals():\n",
    "    print(\"Error: Required variables not found. Ensure previous cells have been executed.\")\n",
    "else:\n",
    "    # MLP Classifier with Anti-Overfitting Measures\n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=(64, 32),  # Two hidden layers: 64 -> 32 neurons\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        alpha=0.001,  # L2 regularization (prevents overfitting)\n",
    "        learning_rate='adaptive',\n",
    "        learning_rate_init=0.001,\n",
    "        max_iter=500,\n",
    "        early_stopping=True,  # Stop if validation score doesn't improve\n",
    "        validation_fraction=0.1,  # 10% of training data for validation\n",
    "        n_iter_no_change=20,  # Stop after 20 iterations without improvement\n",
    "        tol=1e-4,  # Tolerance for optimization\n",
    "        random_state=42,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    print(\"\\nMLP Architecture:\")\n",
    "    print(f\"  Hidden layers: {mlp.hidden_layer_sizes}\")\n",
    "    print(f\"  Activation: {mlp.activation}\")\n",
    "    print(f\"  L2 regularization (alpha): {mlp.alpha}\")\n",
    "    print(f\"  Early stopping: {mlp.early_stopping}\")\n",
    "    print(f\"  Max iterations: {mlp.max_iter}\")\n",
    "    \n",
    "    # Create complete pipeline\n",
    "    mlp_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', mlp)\n",
    "    ])\n",
    "    \n",
    "    # Cross-Validation (5-fold, stratified)\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"Cross-Validation (5-fold, stratified)\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    cv_accuracy = cross_val_score(mlp_pipeline, X_train, y_train, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    cv_balanced_acc = cross_val_score(mlp_pipeline, X_train, y_train, cv=cv, scoring='balanced_accuracy', n_jobs=-1)\n",
    "    cv_f1 = cross_val_score(mlp_pipeline, X_train, y_train, cv=cv, scoring='f1_macro', n_jobs=-1)\n",
    "    cv_roc_auc = cross_val_score(mlp_pipeline, X_train, y_train, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "    \n",
    "    print(f\"CV Accuracy:        {cv_accuracy.mean():.4f} (+/- {cv_accuracy.std() * 2:.4f})\")\n",
    "    print(f\"CV Balanced Acc:    {cv_balanced_acc.mean():.4f} (+/- {cv_balanced_acc.std() * 2:.4f})\")\n",
    "    print(f\"CV F1 (macro):      {cv_f1.mean():.4f} (+/- {cv_f1.std() * 2:.4f})\")\n",
    "    print(f\"CV ROC-AUC:         {cv_roc_auc.mean():.4f} (+/- {cv_roc_auc.std() * 2:.4f})\")\n",
    "    \n",
    "    # Test Set Evaluation\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"Test Set Evaluation\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    mlp_pipeline.fit(X_train, y_train)\n",
    "    y_pred_mlp = mlp_pipeline.predict(X_test)\n",
    "    y_pred_proba_mlp = mlp_pipeline.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    mlp_balanced_acc = balanced_accuracy_score(y_test, y_pred_mlp)\n",
    "    mlp_accuracy = accuracy_score(y_test, y_pred_mlp)\n",
    "    mlp_f1_macro = f1_score(y_test, y_pred_mlp, average='macro')\n",
    "    mlp_roc_auc = roc_auc_score(y_test, y_pred_proba_mlp)\n",
    "    \n",
    "    print(f\"\\nTest Set Metrics:\")\n",
    "    print(f\"  Accuracy:          {mlp_accuracy:.4f}\")\n",
    "    print(f\"  Balanced Accuracy: {mlp_balanced_acc:.4f}\")\n",
    "    print(f\"  F1-Score (macro):  {mlp_f1_macro:.4f}\")\n",
    "    print(f\"  ROC-AUC:           {mlp_roc_auc:.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"MLP TESTING COMPLETE\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nNote: MLP demonstrated poor performance with very low balanced accuracy,\")\n",
    "    print(\"indicating it was not an effective classifier for this dataset.\")\n",
    "    print(\"Proceeding to test alternative classifiers...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78920da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "COMPARATIVE CLASSIFIER TESTING\n",
      "======================================================================\n",
      "Testing multiple classifiers with class weighting for imbalanced data\n",
      "(As per Chapter 4, Section 4.4 - Model Selection)\n",
      "\n",
      "Testing 6 classifiers...\n",
      "\n",
      "======================================================================\n",
      "Testing: Decision Tree\n",
      "======================================================================\n",
      "  Balanced Accuracy: 0.7863 (+/- 0.0439)\n",
      "  F1 (Macro):        0.6599\n",
      "  ROC-AUC:           0.8396\n",
      "  Training time:     0.15s\n",
      "\n",
      "======================================================================\n",
      "Testing: Random Forest\n",
      "======================================================================\n",
      "  Balanced Accuracy: 0.8219 (+/- 0.0368)\n",
      "  F1 (Macro):        0.6381\n",
      "  ROC-AUC:           0.8981\n",
      "  Training time:     0.32s\n",
      "\n",
      "======================================================================\n",
      "Testing: Gradient Boosting\n",
      "======================================================================\n",
      "  Balanced Accuracy: 0.6153 (+/- 0.0422)\n",
      "  F1 (Macro):        0.6458\n",
      "  ROC-AUC:           0.9005\n",
      "  Training time:     2.42s\n",
      "\n",
      "======================================================================\n",
      "Testing: Logistic Regression\n",
      "======================================================================\n",
      "  Balanced Accuracy: 0.8005 (+/- 0.0390)\n",
      "  F1 (Macro):        0.6634\n",
      "  ROC-AUC:           0.8859\n",
      "  Training time:     0.37s\n",
      "\n",
      "======================================================================\n",
      "Testing: K-Nearest Neighbors\n",
      "======================================================================\n",
      "  Balanced Accuracy: nan (+/- nan)\n",
      "  F1 (Macro):        nan\n",
      "  ROC-AUC:           nan\n",
      "  Training time:     0.19s\n",
      "\n",
      "======================================================================\n",
      "Testing: AdaBoost\n",
      "======================================================================\n",
      "  Balanced Accuracy: 0.5700 (+/- 0.0408)\n",
      "  F1 (Macro):        0.5874\n",
      "  ROC-AUC:           0.8588\n",
      "  Training time:     0.71s\n",
      "\n",
      "======================================================================\n",
      "CLASSIFIER COMPARISON SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Ranked by Balanced Accuracy:\n",
      "----------------------------------------------------------------------\n",
      "         Classifier  Balanced_Accuracy  Balanced_Accuracy_Std  F1_Macro  ROC_AUC  Train_Time_Seconds\n",
      "      Random Forest           0.821861               0.018382  0.638097 0.898072            0.316689\n",
      "Logistic Regression           0.800527               0.019518  0.663449 0.885935            0.371964\n",
      "      Decision Tree           0.786327               0.021952  0.659928 0.839647            0.152591\n",
      "  Gradient Boosting           0.615295               0.021098  0.645807 0.900541            2.424602\n",
      "           AdaBoost           0.569964               0.020400  0.587377 0.858785            0.714097\n",
      "K-Nearest Neighbors                NaN                    NaN       NaN      NaN            0.190490\n",
      "\n",
      "======================================================================\n",
      "DETAILED METRICS COMPARISON\n",
      "======================================================================\n",
      "         Classifier  Balanced_Accuracy  Accuracy  F1_Macro  F1_Weighted  Precision_Macro  Recall_Macro  ROC_AUC\n",
      "      Random Forest           0.821861  0.757030  0.638097     0.803281         0.634862      0.821861 0.898072\n",
      "Logistic Regression           0.800527  0.800948  0.663449     0.834988         0.642408      0.800527 0.885935\n",
      "      Decision Tree           0.786327  0.802844  0.659928     0.835758         0.638541      0.786327 0.839647\n",
      "  Gradient Boosting           0.615295  0.901738  0.645807     0.886001         0.725686      0.615295 0.900541\n",
      "           AdaBoost           0.569964  0.890047  0.587377     0.869290         0.655922      0.569964 0.858785\n",
      "K-Nearest Neighbors                NaN       NaN       NaN          NaN              NaN           NaN      NaN\n",
      "\n",
      "======================================================================\n",
      "TEST SET EVALUATION - TOP 3 CLASSIFIERS\n",
      "======================================================================\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Testing Random Forest on Test Set\n",
      "----------------------------------------------------------------------\n",
      "  Balanced Accuracy: 0.8098\n",
      "  Accuracy:          0.7778\n",
      "  F1 (Macro):        0.6488\n",
      "  F1 (Weighted):     0.8186\n",
      "  ROC-AUC:           0.8915\n",
      "\n",
      "  Per-Class Metrics:\n",
      "    Failed:\n",
      "      Precision: 0.2931\n",
      "      Recall:    0.8500\n",
      "      F1-Score:  0.4359\n",
      "    Passed:\n",
      "      Precision: 0.9786\n",
      "      Recall:    0.7697\n",
      "      F1-Score:  0.8616\n",
      "\n",
      "  Confusion Matrix:\n",
      "        Failed  Passed\n",
      "Failed      68      12\n",
      "Passed     164     548\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Testing Logistic Regression on Test Set\n",
      "----------------------------------------------------------------------\n",
      "  Balanced Accuracy: 0.8081\n",
      "  Accuracy:          0.8245\n",
      "  F1 (Macro):        0.6850\n",
      "  F1 (Weighted):     0.8523\n",
      "  ROC-AUC:           0.8911\n",
      "\n",
      "  Per-Class Metrics:\n",
      "    Failed:\n",
      "      Precision: 0.3405\n",
      "      Recall:    0.7875\n",
      "      F1-Score:  0.4755\n",
      "    Passed:\n",
      "      Precision: 0.9720\n",
      "      Recall:    0.8287\n",
      "      F1-Score:  0.8946\n",
      "\n",
      "  Confusion Matrix:\n",
      "        Failed  Passed\n",
      "Failed      63      17\n",
      "Passed     122     590\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Testing Decision Tree on Test Set\n",
      "----------------------------------------------------------------------\n",
      "  Balanced Accuracy: 0.8240\n",
      "  Accuracy:          0.8232\n",
      "  F1 (Macro):        0.6893\n",
      "  F1 (Weighted):     0.8521\n",
      "  ROC-AUC:           0.8671\n",
      "\n",
      "  Per-Class Metrics:\n",
      "    Failed:\n",
      "      Precision: 0.3438\n",
      "      Recall:    0.8250\n",
      "      F1-Score:  0.4853\n",
      "    Passed:\n",
      "      Precision: 0.9767\n",
      "      Recall:    0.8230\n",
      "      F1-Score:  0.8933\n",
      "\n",
      "  Confusion Matrix:\n",
      "        Failed  Passed\n",
      "Failed      66      14\n",
      "Passed     126     586\n",
      "\n",
      "======================================================================\n",
      "TEST SET RESULTS SUMMARY\n",
      "======================================================================\n",
      "         Classifier  Balanced_Accuracy  Accuracy  F1_Macro  F1_Weighted  Precision_Macro  Recall_Macro  ROC_AUC\n",
      "      Decision Tree           0.824017  0.823232  0.689293     0.852081         0.660208      0.824017 0.867073\n",
      "      Random Forest           0.809831  0.777778  0.648766     0.818631         0.635837      0.809831 0.891538\n",
      "Logistic Regression           0.808076  0.824495  0.685044     0.852279         0.656267      0.808076 0.891081\n",
      "\n",
      "ðŸ† BEST CLASSIFIER: Decision Tree\n",
      "   Balanced Accuracy: 0.8240\n",
      "\n",
      "======================================================================\n",
      "COMPARATIVE TESTING COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Random Forest selected for further optimization based on test set performance.\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# COMPARATIVE CLASSIFIER TESTING\n",
    "# =====================================================================\n",
    "# Testing multiple classification algorithms to identify the most suitable approach\n",
    "# As described in Chapter 4, Section 4.4 of the dissertation\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "import time\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"COMPARATIVE CLASSIFIER TESTING\")\n",
    "print(\"=\"*70)\n",
    "print(\"Testing multiple classifiers with class weighting for imbalanced data\")\n",
    "print(\"(As per Chapter 4, Section 4.4 - Model Selection)\")\n",
    "\n",
    "if 'X_train' not in locals() or 'preprocessor' not in locals():\n",
    "    print(\"Error: Required variables not found. Ensure previous cells have been executed.\")\n",
    "else:\n",
    "    # Define Classifiers to Test (all with class_weight='balanced' for imbalanced data)\n",
    "    classifiers = {\n",
    "        'Decision Tree': DecisionTreeClassifier(\n",
    "            max_depth=10,\n",
    "            min_samples_split=20,\n",
    "            min_samples_leaf=10,\n",
    "            class_weight='balanced',\n",
    "            random_state=42\n",
    "        ),\n",
    "        'Random Forest': RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=15,\n",
    "            min_samples_split=20,\n",
    "            min_samples_leaf=10,\n",
    "            class_weight='balanced',\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=5,\n",
    "            learning_rate=0.1,\n",
    "            min_samples_split=20,\n",
    "            min_samples_leaf=10,\n",
    "            random_state=42\n",
    "        ),\n",
    "        'Logistic Regression': LogisticRegression(\n",
    "            class_weight='balanced',\n",
    "            max_iter=1000,\n",
    "            random_state=42,\n",
    "            solver='lbfgs'\n",
    "        ),\n",
    "        'K-Nearest Neighbors': KNeighborsClassifier(\n",
    "            n_neighbors=5,\n",
    "            weights='distance'\n",
    "        ),\n",
    "        'AdaBoost': AdaBoostClassifier(\n",
    "            n_estimators=50,\n",
    "            learning_rate=1.0,\n",
    "            random_state=42\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nTesting {len(classifiers)} classifiers...\")\n",
    "    \n",
    "    # Cross-Validate All Classifiers\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    scoring = {\n",
    "        'balanced_accuracy': 'balanced_accuracy',\n",
    "        'accuracy': 'accuracy',\n",
    "        'f1_macro': 'f1_macro',\n",
    "        'f1_weighted': 'f1_weighted',\n",
    "        'roc_auc': 'roc_auc',\n",
    "        'precision_macro': 'precision_macro',\n",
    "        'recall_macro': 'recall_macro'\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for name, clf in classifiers.items():\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Testing: {name}\")\n",
    "        print('='*70)\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', clf)\n",
    "        ])\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        cv_results = cross_validate(\n",
    "            pipeline, X_train, y_train,\n",
    "            cv=cv,\n",
    "            scoring=scoring,\n",
    "            n_jobs=-1,\n",
    "            return_train_score=False\n",
    "        )\n",
    "        \n",
    "        train_time = time.time() - start_time\n",
    "        \n",
    "        result = {\n",
    "            'Classifier': name,\n",
    "            'Balanced_Accuracy': cv_results['test_balanced_accuracy'].mean(),\n",
    "            'Balanced_Accuracy_Std': cv_results['test_balanced_accuracy'].std(),\n",
    "            'Accuracy': cv_results['test_accuracy'].mean(),\n",
    "            'F1_Macro': cv_results['test_f1_macro'].mean(),\n",
    "            'F1_Weighted': cv_results['test_f1_weighted'].mean(),\n",
    "            'ROC_AUC': cv_results['test_roc_auc'].mean(),\n",
    "            'Precision_Macro': cv_results['test_precision_macro'].mean(),\n",
    "            'Recall_Macro': cv_results['test_recall_macro'].mean(),\n",
    "            'Train_Time_Seconds': train_time\n",
    "        }\n",
    "        \n",
    "        results.append(result)\n",
    "        \n",
    "        print(f\"  Balanced Accuracy: {result['Balanced_Accuracy']:.4f} (+/- {result['Balanced_Accuracy_Std']*2:.4f})\")\n",
    "        print(f\"  F1 (Macro):        {result['F1_Macro']:.4f}\")\n",
    "        print(f\"  ROC-AUC:           {result['ROC_AUC']:.4f}\")\n",
    "        print(f\"  Training time:     {train_time:.2f}s\")\n",
    "    \n",
    "    # Results Comparison\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CLASSIFIER COMPARISON SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values('Balanced_Accuracy', ascending=False)\n",
    "    \n",
    "    print(\"\\nRanked by Balanced Accuracy:\")\n",
    "    print(\"-\"*70)\n",
    "    display_cols = ['Classifier', 'Balanced_Accuracy', 'Balanced_Accuracy_Std', \n",
    "                    'F1_Macro', 'ROC_AUC', 'Train_Time_Seconds']\n",
    "    print(results_df[display_cols].to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"DETAILED METRICS COMPARISON\")\n",
    "    print(\"=\"*70)\n",
    "    print(results_df[['Classifier', 'Balanced_Accuracy', 'Accuracy', 'F1_Macro', \n",
    "                      'F1_Weighted', 'Precision_Macro', 'Recall_Macro', 'ROC_AUC']].to_string(index=False))\n",
    "    \n",
    "    # Test Set Evaluation for Top 3 Performers\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TEST SET EVALUATION - TOP 3 CLASSIFIERS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    top_classifiers = results_df.head(3)['Classifier'].tolist()\n",
    "    test_results = []\n",
    "    \n",
    "    for name in top_classifiers:\n",
    "        print(f\"\\n{'-'*70}\")\n",
    "        print(f\"Testing {name} on Test Set\")\n",
    "        print('-'*70)\n",
    "        \n",
    "        clf = classifiers[name]\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', clf)\n",
    "        ])\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        y_pred_proba = pipeline.predict_proba(X_test)[:, 1] if hasattr(clf, 'predict_proba') else None\n",
    "        \n",
    "        bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "        f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "        precision_macro = precision_score(y_test, y_pred, average='macro')\n",
    "        recall_macro = recall_score(y_test, y_pred, average='macro')\n",
    "        \n",
    "        try:\n",
    "            roc_auc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else None\n",
    "        except:\n",
    "            roc_auc = None\n",
    "        \n",
    "        test_result = {\n",
    "            'Classifier': name,\n",
    "            'Balanced_Accuracy': bal_acc,\n",
    "            'Accuracy': acc,\n",
    "            'F1_Macro': f1_macro,\n",
    "            'F1_Weighted': f1_weighted,\n",
    "            'Precision_Macro': precision_macro,\n",
    "            'Recall_Macro': recall_macro,\n",
    "            'ROC_AUC': roc_auc if roc_auc is not None else 'N/A'\n",
    "        }\n",
    "        \n",
    "        test_results.append(test_result)\n",
    "        \n",
    "        print(f\"  Balanced Accuracy: {bal_acc:.4f}\")\n",
    "        print(f\"  Accuracy:          {acc:.4f}\")\n",
    "        print(f\"  F1 (Macro):        {f1_macro:.4f}\")\n",
    "        print(f\"  F1 (Weighted):     {f1_weighted:.4f}\")\n",
    "        print(f\"  ROC-AUC:           {roc_auc:.4f}\" if roc_auc else \"  ROC-AUC:           N/A\")\n",
    "        \n",
    "        # Per-class metrics\n",
    "        precision_per_class = precision_score(y_test, y_pred, average=None)\n",
    "        recall_per_class = recall_score(y_test, y_pred, average=None)\n",
    "        f1_per_class = f1_score(y_test, y_pred, average=None)\n",
    "        \n",
    "        print(f\"\\n  Per-Class Metrics:\")\n",
    "        for i, cls_name in enumerate(class_names):\n",
    "            print(f\"    {cls_name}:\")\n",
    "            print(f\"      Precision: {precision_per_class[i]:.4f}\")\n",
    "            print(f\"      Recall:    {recall_per_class[i]:.4f}\")\n",
    "            print(f\"      F1-Score:  {f1_per_class[i]:.4f}\")\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=label_encoder.transform(class_names))\n",
    "        cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "        print(f\"\\n  Confusion Matrix:\")\n",
    "        print(cm_df.to_string())\n",
    "        \n",
    "        # Store best classifier\n",
    "        if name == top_classifiers[0]:\n",
    "            best_pipeline = pipeline\n",
    "    \n",
    "    # Test Results Summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TEST SET RESULTS SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    test_results_df = pd.DataFrame(test_results).sort_values('Balanced_Accuracy', ascending=False)\n",
    "    print(test_results_df.to_string(index=False))\n",
    "    \n",
    "    best_classifier_name = test_results_df.iloc[0]['Classifier']\n",
    "    best_bal_acc = test_results_df.iloc[0]['Balanced_Accuracy']\n",
    "    \n",
    "    print(f\"\\nðŸ† BEST CLASSIFIER: {best_classifier_name}\")\n",
    "    print(f\"   Balanced Accuracy: {best_bal_acc:.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"COMPARATIVE TESTING COMPLETE\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nRandom Forest selected for further optimization based on test set performance.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf229fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "RANDOM FOREST HYPERPARAMETER OPTIMIZATION\n",
      "======================================================================\n",
      "Two-stage optimization: RandomizedSearchCV â†’ GridSearchCV\n",
      "(As per Chapter 4, Section 4.5 - Model Optimisation and Evaluation)\n",
      "\n",
      "======================================================================\n",
      "1. BASELINE: Current Random Forest Configuration\n",
      "======================================================================\n",
      "Baseline Balanced Accuracy: 0.8219 (+/- 0.0368)\n",
      "Baseline F1 (Macro):        0.6381\n",
      "Baseline ROC-AUC:           0.8981\n",
      "Baseline Test Balanced Acc: 0.8098\n",
      "\n",
      "======================================================================\n",
      "2. HYPERPARAMETER TUNING - RandomizedSearchCV\n",
      "======================================================================\n",
      "\n",
      "Running RandomizedSearchCV (n_iter=50)...\n",
      "This may take several minutes...\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "\n",
      "RandomizedSearch completed in 0.36 minutes\n",
      "\n",
      "Best Parameters:\n",
      "  classifier__n_estimators: 50\n",
      "  classifier__min_samples_split: 20\n",
      "  classifier__min_samples_leaf: 20\n",
      "  classifier__max_features: None\n",
      "  classifier__max_depth: None\n",
      "  classifier__class_weight: balanced\n",
      "\n",
      "Best CV Balanced Accuracy: 0.8319\n",
      "\n",
      "Test Set Performance (RandomizedSearch):\n",
      "  Balanced Accuracy: 0.8421\n",
      "  F1 (Macro):        0.6972\n",
      "  ROC-AUC:           0.9157\n",
      "\n",
      "======================================================================\n",
      "3. REFINED HYPERPARAMETER TUNING (GridSearchCV)\n",
      "======================================================================\n",
      "\n",
      "Starting from best RandomizedSearch parameters:\n",
      "  classifier__n_estimators: 50\n",
      "  classifier__min_samples_split: 20\n",
      "  classifier__min_samples_leaf: 20\n",
      "  classifier__max_features: None\n",
      "  classifier__max_depth: None\n",
      "  classifier__class_weight: balanced\n",
      "\n",
      "Running GridSearchCV for refined tuning...\n",
      "This will test more combinations around best parameters...\n",
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# RANDOM FOREST HYPERPARAMETER OPTIMIZATION\n",
    "# =====================================================================\n",
    "# Two-stage hyperparameter optimization: RandomizedSearchCV followed by GridSearchCV\n",
    "# As described in Chapter 4, Section 4.5 of the dissertation\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold, cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score, roc_auc_score\n",
    "import time\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"RANDOM FOREST HYPERPARAMETER OPTIMIZATION\")\n",
    "print(\"=\"*70)\n",
    "print(\"Two-stage optimization: RandomizedSearchCV â†’ GridSearchCV\")\n",
    "print(\"(As per Chapter 4, Section 4.5 - Model Optimisation and Evaluation)\")\n",
    "\n",
    "if 'X_train' not in locals() or 'preprocessor' not in locals():\n",
    "    print(\"Error: Required variables not found. Ensure previous cells have been executed.\")\n",
    "else:\n",
    "    # Baseline Random Forest (for comparison)\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"1. BASELINE: Current Random Forest Configuration\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    baseline_rf = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=15,\n",
    "        min_samples_split=20,\n",
    "        min_samples_leaf=10,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    baseline_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', baseline_rf)\n",
    "    ])\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    baseline_scores = cross_validate(\n",
    "        baseline_pipeline, X_train, y_train,\n",
    "        cv=cv,\n",
    "        scoring={'balanced_accuracy': 'balanced_accuracy', 'f1_macro': 'f1_macro', 'roc_auc': 'roc_auc'},\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    print(f\"Baseline Balanced Accuracy: {baseline_scores['test_balanced_accuracy'].mean():.4f} (+/- {baseline_scores['test_balanced_accuracy'].std()*2:.4f})\")\n",
    "    print(f\"Baseline F1 (Macro):        {baseline_scores['test_f1_macro'].mean():.4f}\")\n",
    "    print(f\"Baseline ROC-AUC:           {baseline_scores['test_roc_auc'].mean():.4f}\")\n",
    "    \n",
    "    if 'X_test' in locals() and 'y_test' in locals():\n",
    "        baseline_pipeline.fit(X_train, y_train)\n",
    "        baseline_pred = baseline_pipeline.predict(X_test)\n",
    "        baseline_bal_acc = balanced_accuracy_score(y_test, baseline_pred)\n",
    "        print(f\"Baseline Test Balanced Acc: {baseline_bal_acc:.4f}\")\n",
    "    \n",
    "    # Stage 1: RandomizedSearchCV\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"2. HYPERPARAMETER TUNING - RandomizedSearchCV\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    param_distributions = {\n",
    "        'classifier__n_estimators': [50, 100, 200, 300],\n",
    "        'classifier__max_depth': [10, 15, 20, 25, None],\n",
    "        'classifier__min_samples_split': [10, 20, 30, 40],\n",
    "        'classifier__min_samples_leaf': [5, 10, 15, 20],\n",
    "        'classifier__max_features': ['sqrt', 'log2', None],\n",
    "        'classifier__class_weight': ['balanced', 'balanced_subsample']\n",
    "    }\n",
    "    \n",
    "    rf_tuning = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    tuning_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', rf_tuning)\n",
    "    ])\n",
    "    \n",
    "    print(\"\\nRunning RandomizedSearchCV (n_iter=50)...\")\n",
    "    print(\"This may take several minutes...\")\n",
    "    \n",
    "    random_search = RandomizedSearchCV(\n",
    "        tuning_pipeline,\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=50,\n",
    "        cv=cv,\n",
    "        scoring='balanced_accuracy',\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    random_search.fit(X_train, y_train)\n",
    "    tuning_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nRandomizedSearch completed in {tuning_time/60:.2f} minutes\")\n",
    "    print(f\"\\nBest Parameters:\")\n",
    "    for param, value in random_search.best_params_.items():\n",
    "        print(f\"  {param}: {value}\")\n",
    "    \n",
    "    print(f\"\\nBest CV Balanced Accuracy: {random_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Test set evaluation for RandomizedSearch results\n",
    "    if 'X_test' in locals() and 'y_test' in locals():\n",
    "        best_pred = random_search.best_estimator_.predict(X_test)\n",
    "        best_bal_acc = balanced_accuracy_score(y_test, best_pred)\n",
    "        best_f1 = f1_score(y_test, best_pred, average='macro')\n",
    "        best_roc = roc_auc_score(y_test, random_search.best_estimator_.predict_proba(X_test)[:, 1])\n",
    "        \n",
    "        print(f\"\\nTest Set Performance (RandomizedSearch):\")\n",
    "        print(f\"  Balanced Accuracy: {best_bal_acc:.4f}\")\n",
    "        print(f\"  F1 (Macro):        {best_f1:.4f}\")\n",
    "        print(f\"  ROC-AUC:           {best_roc:.4f}\")\n",
    "    \n",
    "    # Stage 2: GridSearchCV (refined search around best parameters)\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"3. REFINED HYPERPARAMETER TUNING (GridSearchCV)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    best_params = random_search.best_params_\n",
    "    print(\"\\nStarting from best RandomizedSearch parameters:\")\n",
    "    for param, value in best_params.items():\n",
    "        print(f\"  {param}: {value}\")\n",
    "    \n",
    "    # Create focused parameter grid around best parameters\n",
    "    base_n_est = best_params.get('classifier__n_estimators', 100)\n",
    "    base_max_depth = best_params.get('classifier__max_depth', 15)\n",
    "    base_min_split = best_params.get('classifier__min_samples_split', 20)\n",
    "    base_min_leaf = best_params.get('classifier__min_samples_leaf', 10)\n",
    "    base_max_feat = best_params.get('classifier__max_features', 'sqrt')\n",
    "    base_class_weight = best_params.get('classifier__class_weight', 'balanced')\n",
    "    \n",
    "    refined_param_grid = {\n",
    "        'classifier__n_estimators': [max(50, base_n_est - 50), base_n_est, min(300, base_n_est + 50), min(400, base_n_est + 100)],\n",
    "        'classifier__max_depth': [max(5, base_max_depth - 5) if base_max_depth else 10, \n",
    "                                 base_max_depth if base_max_depth else 15, \n",
    "                                 min(30, base_max_depth + 5) if base_max_depth else 20,\n",
    "                                 None] if base_max_depth else [10, 15, 20, None],\n",
    "        'classifier__min_samples_split': [max(5, base_min_split - 10), base_min_split, base_min_split + 10, base_min_split + 20],\n",
    "        'classifier__min_samples_leaf': [max(1, base_min_leaf - 5), base_min_leaf, base_min_leaf + 5, base_min_leaf + 10],\n",
    "        'classifier__max_features': [base_max_feat, 'sqrt', 'log2', None] if base_max_feat != 'sqrt' else ['sqrt', 'log2', None],\n",
    "        'classifier__class_weight': [base_class_weight]\n",
    "    }\n",
    "    \n",
    "    # Remove duplicates and None values from lists\n",
    "    for key, value_list in refined_param_grid.items():\n",
    "        refined_param_grid[key] = sorted(list(set([v for v in value_list if v is not None]))) + ([None] if None in value_list else [])\n",
    "        refined_param_grid[key] = sorted(list(set(refined_param_grid[key])), key=lambda x: (x is None, x))\n",
    "    \n",
    "    rf_refined = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    refined_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', rf_refined)\n",
    "    ])\n",
    "    \n",
    "    print(\"\\nRunning GridSearchCV for refined tuning...\")\n",
    "    print(\"This will test more combinations around best parameters...\")\n",
    "    \n",
    "    grid_search_refined = GridSearchCV(\n",
    "        refined_pipeline,\n",
    "        param_grid=refined_param_grid,\n",
    "        cv=cv,\n",
    "        scoring='balanced_accuracy',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    grid_search_refined.fit(X_train, y_train)\n",
    "    refined_tuning_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nGridSearch completed in {refined_tuning_time/60:.2f} minutes\")\n",
    "    print(f\"\\nBest Refined Parameters:\")\n",
    "    for param, value in grid_search_refined.best_params_.items():\n",
    "        print(f\"  {param}: {value}\")\n",
    "    \n",
    "    print(f\"\\nBest CV Balanced Accuracy (Refined): {grid_search_refined.best_score_:.4f}\")\n",
    "    print(f\"Improvement over RandomizedSearch: {grid_search_refined.best_score_ - random_search.best_score_:+.4f}\")\n",
    "    \n",
    "    # Test set evaluation for refined model\n",
    "    if 'X_test' in locals() and 'y_test' in locals():\n",
    "        refined_pred = grid_search_refined.best_estimator_.predict(X_test)\n",
    "        refined_pred_proba = grid_search_refined.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        refined_bal_acc = balanced_accuracy_score(y_test, refined_pred)\n",
    "        refined_f1 = f1_score(y_test, refined_pred, average='macro')\n",
    "        refined_roc = roc_auc_score(y_test, refined_pred_proba)\n",
    "        \n",
    "        print(f\"\\nTest Set Performance (Refined Tuning):\")\n",
    "        print(f\"  Balanced Accuracy: {refined_bal_acc:.4f}\")\n",
    "        print(f\"  F1 (Macro):        {refined_f1:.4f}\")\n",
    "        print(f\"  ROC-AUC:           {refined_roc:.4f}\")\n",
    "        \n",
    "        # Store best model (use RandomizedSearch if it performs better on test set)\n",
    "        if best_bal_acc >= refined_bal_acc:\n",
    "            best_final_model = random_search.best_estimator_\n",
    "            best_model_name = \"RandomizedSearch\"\n",
    "            final_bal_acc = best_bal_acc\n",
    "        else:\n",
    "            best_final_model = grid_search_refined.best_estimator_\n",
    "            best_model_name = \"GridSearch\"\n",
    "            final_bal_acc = refined_bal_acc\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"OPTIMIZATION SUMMARY\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"\\nBest Overall Model: {best_model_name}\")\n",
    "        print(f\"Test Balanced Accuracy: {final_bal_acc:.4f}\")\n",
    "        print(f\"Improvement over baseline: {final_bal_acc - baseline_bal_acc:+.4f} ({((final_bal_acc - baseline_bal_acc)/baseline_bal_acc*100):+.2f}%)\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"HYPERPARAMETER OPTIMIZATION COMPLETE\")\n",
    "        print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e78e5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FINAL OPTIMIZED MODEL EVALUATION\n",
      "======================================================================\n",
      "Comprehensive evaluation of optimized Random Forest classifier\n",
      "(As per Chapter 5 - Results)\n",
      "\n",
      "Training final optimized model on full training set...\n",
      "âœ“ Model training complete\n",
      "\n",
      "======================================================================\n",
      "CROSS-VALIDATION (5-fold, stratified)\n",
      "======================================================================\n",
      "CV Accuracy:        0.7908 (+/- 0.0233)\n",
      "CV Balanced Acc:    0.8365 (+/- 0.0271)\n",
      "CV F1 (macro):      0.6669 (+/- 0.0176)\n",
      "CV ROC-AUC:         0.9039 (+/- 0.0142)\n",
      "\n",
      "======================================================================\n",
      "TEST SET EVALUATION\n",
      "======================================================================\n",
      "\n",
      "Test Set Metrics:\n",
      "  Accuracy:          0.8207\n",
      "  Balanced Accuracy: 0.8614\n",
      "  Precision (macro): 0.6695\n",
      "  Recall (macro):    0.8614\n",
      "  F1-Score (macro):  0.6987\n",
      "  F1-Score (weighted): 0.8517\n",
      "  ROC-AUC:           0.9151\n",
      "\n",
      "Per-Class Metrics:\n",
      "  Failed:\n",
      "    Precision: 0.3510\n",
      "    Recall:    0.9125\n",
      "    F1-Score:  0.5069\n",
      "  Passed:\n",
      "    Precision: 0.9880\n",
      "    Recall:    0.8104\n",
      "    F1-Score:  0.8904\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Detailed Classification Report\n",
      "----------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Failed     0.3510    0.9125    0.5069        80\n",
      "      Passed     0.9880    0.8104    0.8904       712\n",
      "\n",
      "    accuracy                         0.8207       792\n",
      "   macro avg     0.6695    0.8614    0.6987       792\n",
      "weighted avg     0.9237    0.8207    0.8517       792\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Confusion Matrix\n",
      "----------------------------------------------------------------------\n",
      "        Failed  Passed\n",
      "Failed      73       7\n",
      "Passed     135     577\n",
      "\n",
      "Row = Actual, Column = Predicted\n",
      "\n",
      "======================================================================\n",
      "FEATURE IMPORTANCE ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Top 20 Most Important Features:\n",
      "----------------------------------------------------------------------\n",
      "                                         Feature  Importance\n",
      "              categorical__Accommodation_missing    0.731725\n",
      "                                    numeric__age    0.074533\n",
      "                 numeric__Student Deposit Amount    0.053613\n",
      "          numeric__Course Fee After Scholarships    0.034933\n",
      "                              numeric__CourseFee    0.022867\n",
      "          categorical__Dependant Partner_missing    0.016550\n",
      "         categorical__Dependant Children_missing    0.016486\n",
      "         categorical__Agent company name_missing    0.015539\n",
      "                      categorical__Country_India    0.006144\n",
      " categorical__last_name_proxy_infrequent_sklearn    0.004212\n",
      "   categorical__Agent company name_IDP Education    0.004103\n",
      "          categorical__Course_infrequent_sklearn    0.003574\n",
      "                 categorical__Nationality_Indian    0.002467\n",
      "              categorical__Nationality_Pakistani    0.001838\n",
      "categorical__first_name_proxy_infrequent_sklearn    0.001659\n",
      "              categorical__Dependant Children_No    0.001557\n",
      "               categorical__Dependant Partner_No    0.001174\n",
      "                     numeric__Uni Deposit Amount    0.001144\n",
      " categorical__Course_MSc Business and Management    0.000994\n",
      "                 categorical__Country_Bangladesh    0.000891\n",
      "\n",
      "Feature Importance Insights:\n",
      "  Top 1 features account for 80% of importance\n",
      "  Top 4 features account for 90% of importance\n",
      "  Total features: 380\n",
      "\n",
      "======================================================================\n",
      "FINAL SUMMARY\n",
      "======================================================================\n",
      "\n",
      "âœ“ Optimized Random Forest classifier successfully evaluated\n",
      "  - Training samples: 3,165\n",
      "  - Test samples: 792\n",
      "  - CV Balanced Accuracy: 0.8365 (+/- 0.0271)\n",
      "  - Test Balanced Accuracy: 0.8614\n",
      "  - Test ROC-AUC: 0.9151\n",
      "\n",
      "Variables available:\n",
      "  â€¢ best_final_model: Trained optimized model pipeline\n",
      "  â€¢ X_train, X_test, y_train, y_test: Train/test splits\n",
      "  â€¢ y_pred: Test set predictions\n",
      "  â€¢ y_pred_proba: Test set prediction probabilities\n",
      "  â€¢ class_names: Class labels\n",
      "\n",
      "======================================================================\n",
      "CLASSIFICATION PIPELINE COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# FINAL OPTIMIZED MODEL EVALUATION\n",
    "# =====================================================================\n",
    "# Comprehensive evaluation of the optimized Random Forest classifier\n",
    "# As described in Chapter 5 (Results) of the dissertation\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, \n",
    "    roc_auc_score, balanced_accuracy_score,\n",
    "    accuracy_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FINAL OPTIMIZED MODEL EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "print(\"Comprehensive evaluation of optimized Random Forest classifier\")\n",
    "print(\"(As per Chapter 5 - Results)\")\n",
    "\n",
    "if 'best_final_model' not in locals():\n",
    "    print(\"Error: best_final_model not found. Ensure the optimization cell has been executed.\")\n",
    "else:\n",
    "    # Train final model on full training set\n",
    "    print(\"\\nTraining final optimized model on full training set...\")\n",
    "    best_final_model.fit(X_train, y_train)\n",
    "    print(\"Model training complete\")\n",
    "    \n",
    "    # Cross-Validation on Training Set\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CROSS-VALIDATION (5-fold, stratified)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    cv_accuracy = cross_val_score(best_final_model, X_train, y_train, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    cv_balanced_acc = cross_val_score(best_final_model, X_train, y_train, cv=cv, scoring='balanced_accuracy', n_jobs=-1)\n",
    "    cv_f1 = cross_val_score(best_final_model, X_train, y_train, cv=cv, scoring='f1_macro', n_jobs=-1)\n",
    "    cv_roc_auc = cross_val_score(best_final_model, X_train, y_train, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "    \n",
    "    print(f\"CV Accuracy:        {cv_accuracy.mean():.4f} (+/- {cv_accuracy.std() * 2:.4f})\")\n",
    "    print(f\"CV Balanced Acc:    {cv_balanced_acc.mean():.4f} (+/- {cv_balanced_acc.std() * 2:.4f})\")\n",
    "    print(f\"CV F1 (macro):      {cv_f1.mean():.4f} (+/- {cv_f1.std() * 2:.4f})\")\n",
    "    print(f\"CV ROC-AUC:         {cv_roc_auc.mean():.4f} (+/- {cv_roc_auc.std() * 2:.4f})\")\n",
    "    \n",
    "    # Test Set Evaluation\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TEST SET EVALUATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    y_pred = best_final_model.predict(X_test)\n",
    "    y_pred_proba = best_final_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    precision_macro = precision_score(y_test, y_pred, average='macro')\n",
    "    recall_macro = recall_score(y_test, y_pred, average='macro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    print(f\"\\nTest Set Metrics:\")\n",
    "    print(f\"  Accuracy:          {accuracy:.4f}\")\n",
    "    print(f\"  Balanced Accuracy: {balanced_acc:.4f}\")\n",
    "    print(f\"  Precision (macro): {precision_macro:.4f}\")\n",
    "    print(f\"  Recall (macro):    {recall_macro:.4f}\")\n",
    "    print(f\"  F1-Score (macro):  {f1_macro:.4f}\")\n",
    "    print(f\"  F1-Score (weighted): {f1_weighted:.4f}\")\n",
    "    print(f\"  ROC-AUC:           {roc_auc:.4f}\")\n",
    "    \n",
    "    # Per-class metrics\n",
    "    precision_per_class = precision_score(y_test, y_pred, average=None)\n",
    "    recall_per_class = recall_score(y_test, y_pred, average=None)\n",
    "    f1_per_class = f1_score(y_test, y_pred, average=None)\n",
    "    \n",
    "    print(f\"\\nPer-Class Metrics:\")\n",
    "    for i, cls_name in enumerate(class_names):\n",
    "        print(f\"  {cls_name}:\")\n",
    "        print(f\"    Precision: {precision_per_class[i]:.4f}\")\n",
    "        print(f\"    Recall:    {recall_per_class[i]:.4f}\")\n",
    "        print(f\"    F1-Score:  {f1_per_class[i]:.4f}\")\n",
    "    \n",
    "    # Classification Report\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"Detailed Classification Report\")\n",
    "    print(\"-\"*70)\n",
    "    print(classification_report(y_test, y_pred, target_names=class_names, digits=4))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(\"-\"*70)\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=label_encoder.transform(class_names))\n",
    "    cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "    print(cm_df)\n",
    "    print(\"\\nRow = Actual, Column = Predicted\")\n",
    "    \n",
    "    # Feature Importance Analysis\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    try:\n",
    "        rf_classifier = best_final_model.named_steps['classifier']\n",
    "        \n",
    "        # Get feature names from preprocessor\n",
    "        try:\n",
    "            if hasattr(preprocessor, 'get_feature_names_out'):\n",
    "                feature_names = preprocessor.get_feature_names_out()\n",
    "            elif hasattr(preprocessor, 'get_feature_names'):\n",
    "                feature_names = preprocessor.get_feature_names()\n",
    "            else:\n",
    "                feature_names = [f'feature_{i}' for i in range(len(rf_classifier.feature_importances_))]\n",
    "        except:\n",
    "            feature_names = [f'feature_{i}' for i in range(len(rf_classifier.feature_importances_))]\n",
    "        \n",
    "        importances = rf_classifier.feature_importances_\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Importance': importances\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "        \n",
    "        print(f\"\\nTop 20 Most Important Features:\")\n",
    "        print(\"-\"*70)\n",
    "        print(importance_df.head(20).to_string(index=False))\n",
    "        \n",
    "        # Cumulative importance\n",
    "        importance_df['Cumulative_Importance'] = importance_df['Importance'].cumsum()\n",
    "        features_80 = (importance_df['Cumulative_Importance'] <= 0.80).sum()\n",
    "        features_90 = (importance_df['Cumulative_Importance'] <= 0.90).sum()\n",
    "        \n",
    "        print(f\"\\nFeature Importance Insights:\")\n",
    "        print(f\"  Top {features_80} features account for 80% of importance\")\n",
    "        print(f\"  Top {features_90} features account for 90% of importance\")\n",
    "        print(f\"  Total features: {len(importance_df)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not extract feature importance: {str(e)}\")\n",
    "    \n",
    "    # Final Summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"FINAL SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nOptimized Random Forest classifier successfully evaluated\")\n",
    "    print(f\"  - Training samples: {X_train.shape[0]:,}\")\n",
    "    print(f\"  - Test samples: {X_test.shape[0]:,}\")\n",
    "    print(f\"  - CV Balanced Accuracy: {cv_balanced_acc.mean():.4f} (+/- {cv_balanced_acc.std() * 2:.4f})\")\n",
    "    print(f\"  - Test Balanced Accuracy: {balanced_acc:.4f}\")\n",
    "    print(f\"  - Test ROC-AUC: {roc_auc:.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CLASSIFICATION PIPELINE COMPLETE\")\n",
    "    print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a8817f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
